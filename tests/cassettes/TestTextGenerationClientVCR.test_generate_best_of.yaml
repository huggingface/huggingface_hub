interactions:
- request:
    body: '{"inputs": "test", "parameters": {"do_sample": true, "max_new_tokens":
      1, "repetition_penalty": null, "return_full_text": false, "stop": [], "seed":
      null, "temperature": null, "top_k": null, "top_p": null, "truncate": null, "typical_p":
      null, "best_of": 2, "watermark": false, "details": true, "decoder_input_details":
      true}, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '342'
      Content-Type:
      - application/json
      user-agent:
      - unknown/None; hf_hub/0.16.0.dev0; python/3.10.6; torch/1.12.1; tensorflow/2.11.0;
        fastcore/1.5.23
    method: POST
    uri: https://router.huggingface.co/hf-inference/models/google/flan-t5-xxl
  response:
    body:
      string: '[{"generated_text":"5","details":{"finish_reason":"length","generated_tokens":1,"seed":2835381823020158940,"prefill":[{"id":0,"text":"<pad>","logprob":null}],"tokens":[{"id":305,"text":"
        5","logprob":-6.0976562,"special":false}],"best_of_sequences":[{"generated_text":"10-","finish_reason":"length","generated_tokens":1,"seed":1621834340256795699,"prefill":[{"id":0,"text":"<pad>","logprob":null}],"tokens":[{"id":9445,"text":"
        10-","logprob":-10.6875,"special":false}]}]}}]'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '474'
      Content-Type:
      - application/json
      Date:
      - Mon, 19 Jun 2023 15:19:38 GMT
      access-control-allow-credentials:
      - 'true'
      vary:
      - Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-time:
      - '110'
      x-compute-type:
      - cache
      x-request-id:
      - YrO0tIq-p_KLVqDmvlPjF
      x-sha:
      - ad196ce8c46191d6a52592960835ff96d30152b5
    status:
      code: 200
      message: OK
version: 1
