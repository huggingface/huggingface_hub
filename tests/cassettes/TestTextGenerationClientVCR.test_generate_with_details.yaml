interactions:
- request:
    body: '{"inputs": "test", "parameters": {"decoder_input_details": true, "details":
      true, "do_sample": false, "max_new_tokens": 1, "return_full_text": false, "stop":
      []}, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '179'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - 197c67b8-3fed-4e3a-bf8f-4f4ce1bf4a83
      user-agent:
      - unknown/None; hf_hub/0.24.0.dev0; python/3.10.12; torch/2.2.1; tensorflow/2.15.0.post1;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/google/flan-t5-xxl
  response:
    body:
      string: '[{"generated_text":"","details":{"finish_reason":"length","generated_tokens":1,"seed":null,"prefill":[{"id":0,"text":"<pad>","logprob":null}],"tokens":[{"id":3,"text":"
        ","logprob":-2.0078125,"special":false}]}}]'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Wed, 05 Jun 2024 10:04:17 GMT
      Transfer-Encoding:
      - chunked
      access-control-allow-credentials:
      - 'true'
      access-control-allow-origin:
      - '*'
      vary:
      - origin, Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-characters:
      - '4'
      x-compute-time:
      - '0.064899795'
      x-compute-type:
      - 2-a10-g
      x-generated-tokens:
      - '1'
      x-inference-time:
      - '64'
      x-prompt-tokens:
      - '2'
      x-queue-time:
      - '0'
      x-request-id:
      - S1BqZrjWRZzJihJGnQV_i
      x-sha:
      - ae7c9136adc7555eeccc78cdd960dfd60fb346ce
      x-time-per-token:
      - '64'
      x-total-time:
      - '64'
      x-validation-time:
      - '0'
    status:
      code: 200
      message: OK
version: 1
