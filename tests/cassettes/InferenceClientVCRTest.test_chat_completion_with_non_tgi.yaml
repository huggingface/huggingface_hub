interactions:
- request:
    body: '{"model": "microsoft/DialoGPT-small", "messages": [{"role": "system", "content":
      "You are a helpful assistant."}, {"role": "user", "content": "What is deep learning?"}],
      "frequency_penalty": null, "logit_bias": null, "logprobs": null, "max_tokens":
      20, "n": null, "presence_penalty": null, "response_format": null, "seed": null,
      "stop": null, "temperature": null, "tool_choice": null, "tool_prompt": null,
      "tools": null, "top_logprobs": null, "top_p": null, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '474'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - a45a2f60-ca49-41ee-b75e-d7164591a9f0
      user-agent:
      - unknown/None; hf_hub/0.24.0.dev0; python/3.10.12; torch/2.3.1; tensorflow/2.17.0;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/microsoft/DialoGPT-small/v1/chat/completions
  response:
    body:
      string: '{"object":"chat.completion","id":"","created":1721743094,"model":"microsoft/DialoGPT-small","system_fingerprint":"2.1.1-sha-4dfdb48","choices":[{"index":0,"message":{"role":"assistant","content":"What
        does deep learning have to do with anything?"},"logprobs":null,"finish_reason":"eos_token"}],"usage":{"prompt_tokens":13,"completion_tokens":11,"total_tokens":24}}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 23 Jul 2024 13:58:14 GMT
      Transfer-Encoding:
      - chunked
      access-control-allow-credentials:
      - 'true'
      access-control-allow-origin:
      - '*'
      vary:
      - origin, access-control-request-method, access-control-request-headers, Origin,
        Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-characters:
      - '76'
      x-compute-time:
      - '0.280570863'
      x-compute-type:
      - cpu
      x-generated-tokens:
      - '11'
      x-inference-time:
      - '280'
      x-prompt-tokens:
      - '1003'
      x-queue-time:
      - '0'
      x-request-id:
      - p21wbqdpHwBb21ze7bqhQ
      x-sha:
      - 49c537161a457d5256512f9d2d38a87d81ae0f0e
      x-time-per-token:
      - '25'
      x-total-time:
      - '280'
      x-validation-time:
      - '0'
    status:
      code: 200
      message: OK
version: 1
